{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download packages\n",
    "import pandas as pd\n",
    "\n",
    "# Load the revisions as a dataframe\n",
    "file_index = 19\n",
    "\n",
    "import_file = 'revisions' + str(file_index) + '_complete.csv'\n",
    "revisions_df = pd.read_csv(import_file)\n",
    "\n",
    "revisions_df.reset_index(inplace = True, drop = True)\n",
    "revisions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the words and find the difference between new and old texts \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "diff_lst = []\n",
    "new_text_lst = []\n",
    "old_text_lst = []\n",
    "index_lst = []\n",
    "i = 0\n",
    "\n",
    "for index, row in tqdm(revisions_df.iterrows()):\n",
    "    if index < 0:\n",
    "        continue\n",
    "    \n",
    "    if pd.isna(row['new_text']):\n",
    "        revisions_df = revisions_df.drop([index])\n",
    "    else:\n",
    "        # remove links\n",
    "        text_new = [re.sub(r'http\\S+', '', row['new_text'])]\n",
    "\n",
    "        # remove all non-alphanumeric strings\n",
    "        text_new = re.sub(r'[\\W_]', ' ', str(text_new))\n",
    "\n",
    "        # remove all words with numbers\n",
    "        text_new = re.sub(r'\\S*\\d+\\S*', ' ', str(text_new))\n",
    "\n",
    "        # remove line break markers \n",
    "        text_new = re.sub(r'\\sn\\s', ' ', str(text_new))\n",
    "\n",
    "        # remove hanging contractions or possessives\n",
    "        text_new = re.sub(r'\\ss\\s', ' ', str(text_new))\n",
    "\n",
    "        # remove excess spaces\n",
    "        text_new = re.sub(' +', ' ', str(text_new))\n",
    "\n",
    "        # convert into single strings\n",
    "        text_new = str(text_new).lower().strip().split(' ')\n",
    "\n",
    "        new_text_lst.append(copy.deepcopy(text_new))\n",
    "        index_lst.append(index)\n",
    "\n",
    "        # repeat for old text\n",
    "        if row['rev_id_prev'] == 0 or not isinstance(row['old_text'], str):\n",
    "            old_text_lst.append([''])\n",
    "        else:\n",
    "            text_old = [re.sub(r'http\\S+', '', row['old_text'])]\n",
    "            text_old = re.sub(r'[\\W_]', ' ', str(text_old))\n",
    "            text_old = re.sub(r'\\S*\\d+\\S*', ' ', str(text_old))\n",
    "            text_old = re.sub(r'\\sn\\s', ' ', str(text_old))\n",
    "            text_old = re.sub(r'\\ss\\s', ' ', str(text_old))\n",
    "            text_old = re.sub(' +', ' ', str(text_old))\n",
    "            text_old = str(text_old).lower().strip().split(' ')\n",
    "            old_text_lst.append(copy.deepcopy(text_old))\n",
    "\n",
    "        # Find the difference between the two texts\n",
    "        add = [x for x in text_new if not x in text_old or text_old.remove(x)]\n",
    "        subtract = [x for x in text_old if not x in text_new or text_new.remove(x)]\n",
    "        diff = add + subtract\n",
    "        diff_lst.append(diff)\n",
    "    \n",
    "revisions_df['diff_text'] = diff_lst\n",
    "revisions_df['new_text'] = new_text_lst\n",
    "revisions_df['old_text'] = old_text_lst\n",
    "\n",
    "revisions_df.to_csv('revisions' + str(file_index) + '_parsed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edits Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine edits to the same page by the same author\n",
    "revisions_df_combined = copy.deepcopy(revisions_df)\n",
    "revisions_df_combined = revisions_df_combined.drop(['redirect', 'ns', 'rev_id', 'timestamp', 'ip', 'username', 'comment', 'byt', 'rev_id_prev'], axis = 1) \n",
    "revisions_df_combined = revisions_df_combined.groupby(['page_id','page_title', 'country', 'org']).agg({'diff_text':'sum'}).reset_index()\n",
    "\n",
    "revisions_df_combined.to_csv('revisions' + str(file_index) + '_read4edits.csv', index=False)\n",
    "revisions_df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp so it can be analyzed\n",
    "import datetime\n",
    "\n",
    "new_df_combined = copy.deepcopy(revisions_df)\n",
    "\n",
    "for index, row in tqdm(new_df_combined.iterrows()):\n",
    "    try:\n",
    "        time_string = row['timestamp']\n",
    "\n",
    "        year = int(time_string[0:4])\n",
    "        month = int(time_string[5:7])\n",
    "        day = int(time_string[8:10])\n",
    "        hour = int(time_string[11:13])\n",
    "        minute = int(time_string[14:16])\n",
    "        second = int(time_string[17:19])\n",
    "\n",
    "        time_val = pd.to_datetime(datetime.datetime(year, month, day, hour, minute, second))\n",
    "        time_placeholder = (datetime.datetime.utcfromtimestamp(0) - time_val).total_seconds()\n",
    "        \n",
    "        new_df_combined.loc[index, 'timestamp'] = time_placeholder\n",
    "    except:\n",
    "        new_df_combined.loc[index, 'timestamp'] = 0\n",
    "\n",
    "new_df_combined.timestamp = new_df_combined.timestamp.astype(float)\n",
    "\n",
    "# Combine pages to the same page by the same author; taking the last edited version of the page by the author\n",
    "new_df_combined = new_df_combined.drop(['redirect', 'ns', 'rev_id', 'ip', 'username', 'comment', 'byt', 'rev_id_prev'], axis = 1) \n",
    "new_df_combined = new_df_combined.groupby(['page_id','page_title', 'country', 'org']).apply(lambda x: x.loc[x.timestamp.idxmax()]).reset_index(drop = True)\n",
    "\n",
    "new_df_combined.to_csv('article' + str(file_index) + '_read4article.csv', index=False)\n",
    "new_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
